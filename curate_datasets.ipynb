{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Model Architectures\n",
    "Custom Torch Models need to be instantiated for evaluation. The model_architectures.py file contains the model architectures so we can abstract it and focus only on the evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using device: cuda\n",
      "['BasicBlock', 'DataLoader', 'F', 'Load', 'ResNetCIFAR', 'ResNetMNIST', 'ResnetSVHN', 'TensorDataset', 'Tester', 'Visualizer', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'cifar_directory', 'conv3x3', 'current_directory', 'device', 'mnist_directory', 'nn', 'np', 'os', 'pd', 'pickle', 'plt', 'scipy', 'svhn_directory', 'torch']\n"
     ]
    }
   ],
   "source": [
    "from model_architectures import *\n",
    "import model_architectures\n",
    "from data_curator import *\n",
    "from attacks import * \n",
    "import csv\n",
    "# Print available classes to verify our model architectures were imported\n",
    "print(dir(model_architectures))\n",
    "\n",
    "flags = ['pgd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Model Weights\n",
    "Using our model artifacts we load the weights back into the model so we have our pre-trained models to test our perturbations against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_resnet_model = ResNetMNIST(BasicBlock, [2, 2, 2, 2], num_classes=10, grayscale=True).to(device)\n",
    "cifar_resnet_model = ResNetCIFAR(BasicBlock, [2, 2, 2, 2], num_classes=10, grayscale=False).to(device)\n",
    "svhn_resnet_model = ResnetSVHN(BasicBlock, [2, 2, 2, 2], num_classes=10, grayscale=False).to(device)\n",
    "\n",
    "#add map_location=torch.device('cpu') if running locally and ur not sai lol\n",
    "device = 'cuda'\n",
    "# mnist_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_mnist_model.pth\", map_location=torch.device(device)))\n",
    "# cifar_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_cifar_model.pth\", map_location=torch.device(device)))\n",
    "# svhn_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_svhn_model.pth\",map_location=torch.device(device)))\n",
    "mnist_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_mnist_model.pth\"))\n",
    "cifar_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_cifar_model.pth\"))\n",
    "svhn_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_svhn_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResnetSVHN(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_resnet_model.eval()\n",
    "cifar_resnet_model.eval()\n",
    "svhn_resnet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "loader = Load()\n",
    "mnist_train_images, mnist_train_labels = loader.load_mnist_train_images()\n",
    "cifar10_train_images, cifar10_train_labels = loader.load_cifar10_train_images()\n",
    "svhn_train_images, svhn_train_labels = loader.load_svhn_train_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_mnist = loader.convert_mnist_numpy_to_tensor(mnist_train_images, mnist_train_labels)\n",
    "train_loader_cifar10 = loader.convert_cifar10_numpy_to_tensor(cifar10_train_images, cifar10_train_labels)\n",
    "train_loader_svhn = loader.convert_svhn_numpy_to_tensor(svhn_train_images, svhn_train_labels)\n",
    "tester = Tester()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curating Data\n",
    "We repurpose our test functions for each attack to only output adversarial examples and the total accuracy from the attack without any hanging print statements. We then run them on the entire dataset, as opposed to a sample of 256, and then store these as CSV files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "curator = Curator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'fgsm' in flags:\n",
    "    fgsm_mnist_accuracy, fgsm_mnist_examples = curator.curate_fgsm(mnist_resnet_model, train_loader_mnist, 0.05)\n",
    "    fgsm_cifar10_accuracy, fgsm_cifar10_examples = curator.curate_fgsm(cifar_resnet_model, train_loader_cifar10, 0.025)\n",
    "    fgsm_svhn_accuracy, fgsm_svhn_examples = curator.curate_fgsm(svhn_resnet_model, train_loader_svhn, 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'fgsm' in flags:\n",
    "    print(fgsm_mnist_accuracy)\n",
    "    print(len(fgsm_mnist_examples))\n",
    "    print(len(fgsm_mnist_examples[0]))\n",
    "    print(fgsm_mnist_examples[0][2].shape)\n",
    "\n",
    "    curator.store_data('augmented_data/fgsm_mnist_augmented_data.csv', fgsm_mnist_examples)\n",
    "    print(fgsm_cifar10_accuracy)\n",
    "    print(len(fgsm_cifar10_examples))\n",
    "    print(len(fgsm_cifar10_examples[0]))\n",
    "    print(fgsm_cifar10_examples[0][2].shape)\n",
    "\n",
    "    curator.store_data('augmented_data/fgsm_cifar10_augmented_data.csv', fgsm_cifar10_examples)\n",
    "    print(fgsm_svhn_accuracy)\n",
    "    print(len(fgsm_svhn_examples))\n",
    "    print(len(fgsm_svhn_examples[0]))\n",
    "    print(fgsm_svhn_examples[0][2].shape)\n",
    "\n",
    "    curator.store_data('augmented_data/fgsm_svhn_augmented_data.csv', fgsm_svhn_examples)\n",
    "\n",
    "images = pd.read_csv('augmented_data/fgsm_mnist_augmented_data.csv')\n",
    "def reshape_image(flat_image):\n",
    "    return np.array(flat_image).reshape(28, 28)\n",
    "\n",
    "\n",
    "# Assuming your DataFrame is called 'data'\n",
    "labels = images.iloc[:, 0]  # Assuming the labels are in the first column\n",
    "images = images.iloc[:, 1:]  # Assuming the image data starts from the second column\n",
    "\n",
    "# Selecting the first image and its label\n",
    "first_image = images.iloc[0]\n",
    "first_label = int(labels.iloc[0])\n",
    "\n",
    "# Reshape the image\n",
    "reshaped_image = reshape_image(first_image)\n",
    "\n",
    "# Display the image with its label\n",
    "plt.imshow(reshaped_image, cmap='gray')\n",
    "plt.title(f\"Label: {first_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
