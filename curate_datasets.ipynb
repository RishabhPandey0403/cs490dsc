{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Model Architectures\n",
    "Custom Torch Models need to be instantiated for evaluation. The model_architectures.py file contains the model architectures so we can abstract it and focus only on the evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using device: cuda\n",
      "['BasicBlock', 'DataLoader', 'F', 'Load', 'ResNetCIFAR', 'ResNetMNIST', 'ResnetSVHN', 'TensorDataset', 'Tester', 'Visualizer', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'cifar_directory', 'conv3x3', 'current_directory', 'device', 'mnist_directory', 'nn', 'np', 'os', 'pd', 'pickle', 'plt', 'scipy', 'svhn_directory', 'torch']\n"
     ]
    }
   ],
   "source": [
    "from model_architectures import *\n",
    "import model_architectures\n",
    "from data_curator import *\n",
    "from attacks import * \n",
    "import csv\n",
    "# Print available classes to verify our model architectures were imported\n",
    "print(dir(model_architectures))\n",
    "\n",
    "flags = ['pgd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Model Weights\n",
    "Using our model artifacts we load the weights back into the model so we have our pre-trained models to test our perturbations against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_resnet_model = ResNetMNIST(BasicBlock, [2, 2, 2, 2], num_classes=10, grayscale=True).to(device)\n",
    "cifar_resnet_model = ResNetCIFAR(BasicBlock, [2, 2, 2, 2], num_classes=10, grayscale=False).to(device)\n",
    "svhn_resnet_model = ResnetSVHN(BasicBlock, [2, 2, 2, 2], num_classes=10, grayscale=False).to(device)\n",
    "\n",
    "#add map_location=torch.device('cpu') if running locally and ur not sai lol\n",
    "device = 'cuda'\n",
    "# mnist_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_mnist_model.pth\", map_location=torch.device(device)))\n",
    "# cifar_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_cifar_model.pth\", map_location=torch.device(device)))\n",
    "# svhn_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_svhn_model.pth\",map_location=torch.device(device)))\n",
    "mnist_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_mnist_model.pth\"))\n",
    "cifar_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_cifar_model.pth\"))\n",
    "svhn_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_svhn_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResnetSVHN(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_resnet_model.eval()\n",
    "cifar_resnet_model.eval()\n",
    "svhn_resnet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "loader = Load()\n",
    "mnist_train_images, mnist_train_labels = loader.load_mnist_train_images()\n",
    "cifar10_train_images, cifar10_train_labels = loader.load_cifar10_train_images()\n",
    "svhn_train_images, svhn_train_labels = loader.load_svhn_train_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_mnist = loader.convert_mnist_numpy_to_tensor(mnist_train_images, mnist_train_labels)\n",
    "train_loader_cifar10 = loader.convert_cifar10_numpy_to_tensor(cifar10_train_images, cifar10_train_labels)\n",
    "train_loader_svhn = loader.convert_svhn_numpy_to_tensor(svhn_train_images, svhn_train_labels)\n",
    "\n",
    "\n",
    "# train_loader_mnist = loader.convert_mnist_numpy_to_tensor(mnist_train_images[:256], mnist_train_labels[:256])\n",
    "# train_loader_cifar10 = loader.convert_cifar10_numpy_to_tensor(cifar10_train_images[:256], cifar10_train_labels[:256])\n",
    "# train_loader_svhn = loader.convert_svhn_numpy_to_tensor(svhn_train_images[:256], svhn_train_labels[:256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curating Data\n",
    "We repurpose our test functions for each attack to only output adversarial examples and the total accuracy from the attack without any hanging print statements. We then run them on the entire dataset, as opposed to a sample of 256, and then store these as CSV files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "curator = Curator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'fgsm' in flags:\n",
    "    fgsm_mnist_accuracy, fgsm_mnist_examples = curator.curate_fgsm(mnist_resnet_model, train_loader_mnist, 0.05)\n",
    "    fgsm_cifar10_accuracy, fgsm_cifar10_examples = curator.curate_fgsm(cifar_resnet_model, train_loader_cifar10, 0.025)\n",
    "    fgsm_svhn_accuracy, fgsm_svhn_examples = curator.curate_fgsm(svhn_resnet_model, train_loader_svhn, 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_image(flat_image, color = False):\n",
    "    if color:\n",
    "        print(flat_image.shape)\n",
    "        image_size = 32\n",
    "\n",
    "        # Split the array into three parts\n",
    "        split_size = flat_image.shape[0] // 3\n",
    "        red_channel = flat_image[:split_size]\n",
    "        green_channel = flat_image[split_size:2*split_size]\n",
    "        blue_channel = flat_image[2*split_size:]\n",
    "        # print(f\"Red Shape: {red_channel.shape}\")\n",
    "        # print(f\"Green Shape: {green_channel.shape}\")\n",
    "        # print(f\"Blue Shape: {blue_channel.shape}\")\n",
    "\n",
    "        # Stack the three parts horizontally\n",
    "        stacked_channels = np.dstack([red_channel, green_channel, blue_channel])\n",
    "        # print(stacked_channels.shape)\n",
    "\n",
    "        # Reshape the stacked array into a 3D array\n",
    "        flat_image = stacked_channels.reshape( image_size, image_size, 3)\n",
    "\n",
    "        return flat_image\n",
    "    return np.array(flat_image).reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7946, 785)\n",
      "(47416, 3073)\n",
      "(3072,)\n",
      "(32, 32, 3)\n",
      "(54354, 3073)\n",
      "(3072,)\n",
      "(32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if 'fgsm' in flags:\n",
    "    print(fgsm_mnist_accuracy)\n",
    "    print(len(fgsm_mnist_examples))\n",
    "    print(len(fgsm_mnist_examples[0]))\n",
    "    print(fgsm_mnist_examples[0][2].shape)\n",
    "\n",
    "    curator.store_data('augmented_data/fgsm_mnist_augmented_data.csv', fgsm_mnist_examples)\n",
    "\n",
    "    print(fgsm_cifar10_accuracy)\n",
    "    print(len(fgsm_cifar10_examples))\n",
    "    print(len(fgsm_cifar10_examples[0]))\n",
    "    print(fgsm_cifar10_examples[0][2].shape)\n",
    "\n",
    "    curator.store_data('augmented_data/fgsm_cifar10_augmented_data.csv', fgsm_cifar10_examples, color = True)\n",
    "\n",
    "    print(fgsm_svhn_accuracy)\n",
    "    print(len(fgsm_svhn_examples))\n",
    "    print(len(fgsm_svhn_examples[0]))\n",
    "    print(fgsm_svhn_examples[0][2].shape)\n",
    "\n",
    "    curator.store_data('augmented_data/fgsm_svhn_augmented_data.csv', fgsm_svhn_examples, color = True)\n",
    "\n",
    "\n",
    "# Load the images from the csv, convert them to h5, and then use the h5 file. \n",
    "if 'fgsm' in flags:\n",
    "    images = pd.read_csv(\"augmented_data/fgsm_mnist_augmented_data.csv\")\n",
    "    images.to_hdf(\"augmented_data/fgsm_mnist_augmented_data.h5\", key='data', mode='w')\n",
    "images = pd.read_hdf('augmented_data/fgsm_mnist_augmented_data.h5')\n",
    "print(images.shape)\n",
    "labels = images.iloc[:, 0]  \n",
    "images = images.iloc[:, 1:]  \n",
    "\n",
    "# Selecting the first image and its label\n",
    "first_image = images.iloc[0]\n",
    "first_label = int(labels.iloc[0])\n",
    "\n",
    "# Reshape the image\n",
    "reshaped_image1 = reshape_image(first_image)\n",
    "\n",
    "if 'fgsm' in flags:\n",
    "    images = pd.read_csv(\"augmented_data/fgsm_cifar10_augmented_data.csv\")\n",
    "    images.to_hdf(\"augmented_data/fgsm_cifar10_augmented_data.h5\", key='data', mode='w')\n",
    "images = pd.read_hdf('augmented_data/fgsm_cifar10_augmented_data.h5')\n",
    "print(images.shape)\n",
    "labels = images.iloc[:, 0] \n",
    "images = images.iloc[:, 1:]\n",
    "\n",
    "# Selecting the first image and its label\n",
    "first_image = images.iloc[0]\n",
    "first_label = int(labels.iloc[0])\n",
    "\n",
    "# Reshape the image\n",
    "reshaped_image2 = reshape_image(np.array(first_image), color = True)\n",
    "print(reshaped_image2.shape)\n",
    "\n",
    "\n",
    "\n",
    "if 'fgsm' in flags:\n",
    "    images = pd.read_csv(\"augmented_data/fgsm_svhn_augmented_data.csv\")\n",
    "    images.to_hdf(\"augmented_data/fgsm_svhn_augmented_data.h5\", key='data', mode='w')\n",
    "images = pd.read_hdf('augmented_data/fgsm_svhn_augmented_data.h5')\n",
    "print(images.shape)\n",
    "labels = images.iloc[:, 0] \n",
    "images = images.iloc[:, 1:]\n",
    "\n",
    "# Selecting the first image and its label\n",
    "first_image = images.iloc[0]\n",
    "first_label = int(labels.iloc[0])\n",
    "\n",
    "# Reshape the image\n",
    "reshaped_image3= reshape_image(np.array(first_image), color = True)\n",
    "print(reshaped_image3.shape)\n",
    "# Display the image with its label\n",
    "plt.imshow(reshaped_image3)\n",
    "plt.title(f\"Label: {first_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
