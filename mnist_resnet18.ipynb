{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: c:\\Users\\Sai\\Work\\cs490\n",
      "MNIST Directory: c:\\Users\\Sai\\Work\\cs490\\MNIST_CSV\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "current_directory = os.getcwd()\n",
    "mnist_directory = os.path.join(current_directory,\"MNIST_CSV\")\n",
    "\n",
    "print(\"Current Directory:\", current_directory)\n",
    "print(\"MNIST Directory:\", mnist_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Enable GPU usage for faster training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining model architecture\n",
    "To apply resnet18 to MNIST data we need to define our model architecture using pytorch. This task has been done by dozens of computer scientists before so finding pre-existing implementations of the architecture was quite easy. In fact, resnet18 is so popular for these tasks that there was an option to import the model altogether without redefining the model architecture but recreating it allows for opportunities for modification later and better interpretability of what the CNN is doing. \n",
    "\n",
    "Residual networks create a block for the input data and pass the original block of data combined with output from the previous layer into the next layer. This prevents loss of data integrity and vanishing gradients as the input gets propagated deeper into the network.\n",
    "\n",
    "<p align=\"center\"><img src=\"images/resnet18ex1.png\" alt=\"Diagram showing the skip block\" width=\"75%\"/> </br> This diagram shows the original block \"skipping\" a layer and being passed as input into the next layer </p>\n",
    "<p align=\"center\"><img src=\"images/resnet18ex2.png\" alt=\"Diagram showing the layers of Resnet18\" width=\"75%\"/></br> This diagram visualizes the internal layers specifications</p>\n",
    "\n",
    "We can see the intricacies of each layer. The data is first convoluted into a block which is passed to other layers. Resnet has 8 layers of convolutional filters before being pooled. In this example, the output is softmaxed but for our purposes we modify it to use a linear output to predict one of the 10 classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture Sourced From: https://github.com/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-resnet18-mnist.ipynb\n",
    "# Resnet Paper: https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf\n",
    "# https://www.researchgate.net/figure/ResNet-18-architecture-20-The-numbers-added-to-the-end-of-ResNet-represent-the_fig2_349241995\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "# Define the BasicBlock\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# Define the ResNet model\n",
    "class ResNetMNIST(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.inplanes = 64\n",
    "        if grayscale:\n",
    "            in_dim = 1\n",
    "        else:\n",
    "            in_dim = 3\n",
    "        super(ResNetMNIST, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n)**.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetMNIST(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the ResNet18 model\n",
    "NUM_CLASSES = 10  # Number of classes in MNIST\n",
    "GRAYSCALE = True  # Since MNIST is grayscale\n",
    "resnet18_model = ResNetMNIST(block=BasicBlock, layers=[2, 2, 2, 2], num_classes=NUM_CLASSES, grayscale=GRAYSCALE)\n",
    "resnet18_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data\n",
    "MNIST data is pretty clean. All we needed to do is open the dataframe from the csv file and extract our data and labels. MNIST will use the grayscale version of this neural network so the pixel values are normalized to a range of 0 to 1. \n",
    "\n",
    "The data is then converted to a tensor dataset and loaded for pytorch. To speed up computation we push the tensors to a GPU if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSVs using pandas\n",
    "mnist_train = pd.read_csv(os.path.join(mnist_directory, \"mnist_train.csv\"), header=None)\n",
    "mnist_train.head()\n",
    "\n",
    "mnist_test = pd.read_csv(os.path.join(mnist_directory, \"mnist_test.csv\"), header=None)\n",
    "mnist_test.head()\n",
    "\n",
    "# Extract labels and pixel values\n",
    "train_labels = mnist_train.iloc[:, 0].values\n",
    "train_images = mnist_train.iloc[:, 1:].values / 255.0  # Normalize pixel values to the range [0, 1]\n",
    "\n",
    "test_labels = mnist_test.iloc[:, 0].values\n",
    "test_images = mnist_test.iloc[:, 1:].values / 255.0  # Normalize pixel values to the range [0, 1]\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_images_tensor = torch.tensor(train_images, dtype=torch.float32)\n",
    "train_labels_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
    "\n",
    "test_images_tensor = torch.tensor(test_images, dtype=torch.float32)\n",
    "test_labels_tensor = torch.tensor(test_labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the images to [batch_size, 1, 28, 28]\n",
    "train_images_tensor = train_images_tensor.view(-1, 1, 28, 28)\n",
    "test_images_tensor = test_images_tensor.view(-1, 1, 28, 28)\n",
    "\n",
    "# Create TensorDataset and DataLoader\n",
    "train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "test_dataset = TensorDataset(test_images_tensor, test_labels_tensor)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Move the data to the GPU\n",
    "train_images_tensor, train_labels_tensor = train_images_tensor.to(device), train_labels_tensor.to(device)\n",
    "test_images_tensor, test_labels_tensor = test_images_tensor.to(device), test_labels_tensor.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "Training the model is straightforward: the resnet18 model is initialized with the learning rate and cross entropy loss function hyperparameters, and then training is run for a certain number of epochs by passing in image data into the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/938], Loss: 0.1655\n",
      "Epoch [1/10], Step [200/938], Loss: 0.1475\n",
      "Epoch [1/10], Step [300/938], Loss: 0.2273\n",
      "Epoch [1/10], Step [400/938], Loss: 0.1939\n",
      "Epoch [1/10], Step [500/938], Loss: 0.1127\n",
      "Epoch [1/10], Step [600/938], Loss: 0.0648\n",
      "Epoch [1/10], Step [700/938], Loss: 0.0885\n",
      "Epoch [1/10], Step [800/938], Loss: 0.0233\n",
      "Epoch [1/10], Step [900/938], Loss: 0.2213\n",
      "Epoch [2/10], Step [100/938], Loss: 0.0450\n",
      "Epoch [2/10], Step [200/938], Loss: 0.0127\n",
      "Epoch [2/10], Step [300/938], Loss: 0.2167\n",
      "Epoch [2/10], Step [400/938], Loss: 0.0187\n",
      "Epoch [2/10], Step [500/938], Loss: 0.0844\n",
      "Epoch [2/10], Step [600/938], Loss: 0.0108\n",
      "Epoch [2/10], Step [700/938], Loss: 0.0418\n",
      "Epoch [2/10], Step [800/938], Loss: 0.0304\n",
      "Epoch [2/10], Step [900/938], Loss: 0.0083\n",
      "Epoch [3/10], Step [100/938], Loss: 0.0695\n",
      "Epoch [3/10], Step [200/938], Loss: 0.1292\n",
      "Epoch [3/10], Step [300/938], Loss: 0.0054\n",
      "Epoch [3/10], Step [400/938], Loss: 0.0238\n",
      "Epoch [3/10], Step [500/938], Loss: 0.0282\n",
      "Epoch [3/10], Step [600/938], Loss: 0.0531\n",
      "Epoch [3/10], Step [700/938], Loss: 0.0242\n",
      "Epoch [3/10], Step [800/938], Loss: 0.0060\n",
      "Epoch [3/10], Step [900/938], Loss: 0.0787\n",
      "Epoch [4/10], Step [100/938], Loss: 0.0195\n",
      "Epoch [4/10], Step [200/938], Loss: 0.0181\n",
      "Epoch [4/10], Step [300/938], Loss: 0.0482\n",
      "Epoch [4/10], Step [400/938], Loss: 0.0018\n",
      "Epoch [4/10], Step [500/938], Loss: 0.0027\n",
      "Epoch [4/10], Step [600/938], Loss: 0.0066\n",
      "Epoch [4/10], Step [700/938], Loss: 0.0322\n",
      "Epoch [4/10], Step [800/938], Loss: 0.0122\n",
      "Epoch [4/10], Step [900/938], Loss: 0.0011\n",
      "Epoch [5/10], Step [100/938], Loss: 0.0015\n",
      "Epoch [5/10], Step [200/938], Loss: 0.0036\n",
      "Epoch [5/10], Step [300/938], Loss: 0.0042\n",
      "Epoch [5/10], Step [400/938], Loss: 0.0124\n",
      "Epoch [5/10], Step [500/938], Loss: 0.0130\n",
      "Epoch [5/10], Step [600/938], Loss: 0.1181\n",
      "Epoch [5/10], Step [700/938], Loss: 0.0405\n",
      "Epoch [5/10], Step [800/938], Loss: 0.2307\n",
      "Epoch [5/10], Step [900/938], Loss: 0.1463\n",
      "Epoch [6/10], Step [100/938], Loss: 0.0075\n",
      "Epoch [6/10], Step [200/938], Loss: 0.0014\n",
      "Epoch [6/10], Step [300/938], Loss: 0.0088\n",
      "Epoch [6/10], Step [400/938], Loss: 0.0026\n",
      "Epoch [6/10], Step [500/938], Loss: 0.0073\n",
      "Epoch [6/10], Step [600/938], Loss: 0.0020\n",
      "Epoch [6/10], Step [700/938], Loss: 0.0016\n",
      "Epoch [6/10], Step [800/938], Loss: 0.0121\n",
      "Epoch [6/10], Step [900/938], Loss: 0.0245\n",
      "Epoch [7/10], Step [100/938], Loss: 0.0027\n",
      "Epoch [7/10], Step [200/938], Loss: 0.0024\n",
      "Epoch [7/10], Step [300/938], Loss: 0.0521\n",
      "Epoch [7/10], Step [400/938], Loss: 0.0251\n",
      "Epoch [7/10], Step [500/938], Loss: 0.0833\n",
      "Epoch [7/10], Step [600/938], Loss: 0.1926\n",
      "Epoch [7/10], Step [700/938], Loss: 0.0024\n",
      "Epoch [7/10], Step [800/938], Loss: 0.0198\n",
      "Epoch [7/10], Step [900/938], Loss: 0.0011\n",
      "Epoch [8/10], Step [100/938], Loss: 0.0616\n",
      "Epoch [8/10], Step [200/938], Loss: 0.0144\n",
      "Epoch [8/10], Step [300/938], Loss: 0.0036\n",
      "Epoch [8/10], Step [400/938], Loss: 0.0299\n",
      "Epoch [8/10], Step [500/938], Loss: 0.0077\n",
      "Epoch [8/10], Step [600/938], Loss: 0.0237\n",
      "Epoch [8/10], Step [700/938], Loss: 0.0006\n",
      "Epoch [8/10], Step [800/938], Loss: 0.0412\n",
      "Epoch [8/10], Step [900/938], Loss: 0.0042\n",
      "Epoch [9/10], Step [100/938], Loss: 0.0027\n",
      "Epoch [9/10], Step [200/938], Loss: 0.0019\n",
      "Epoch [9/10], Step [300/938], Loss: 0.0275\n",
      "Epoch [9/10], Step [400/938], Loss: 0.0025\n",
      "Epoch [9/10], Step [500/938], Loss: 0.0072\n",
      "Epoch [9/10], Step [600/938], Loss: 0.0166\n",
      "Epoch [9/10], Step [700/938], Loss: 0.0202\n",
      "Epoch [9/10], Step [800/938], Loss: 0.0170\n",
      "Epoch [9/10], Step [900/938], Loss: 0.0022\n",
      "Epoch [10/10], Step [100/938], Loss: 0.0039\n",
      "Epoch [10/10], Step [200/938], Loss: 0.0084\n",
      "Epoch [10/10], Step [300/938], Loss: 0.0003\n",
      "Epoch [10/10], Step [400/938], Loss: 0.0026\n",
      "Epoch [10/10], Step [500/938], Loss: 0.0012\n",
      "Epoch [10/10], Step [600/938], Loss: 0.0041\n",
      "Epoch [10/10], Step [700/938], Loss: 0.0172\n",
      "Epoch [10/10], Step [800/938], Loss: 0.0045\n",
      "Epoch [10/10], Step [900/938], Loss: 0.0008\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet18_model.parameters(), lr=0.001)\n",
    "\n",
    "# While training run nvidia-smi in the terminal to check gpu tasks \n",
    "\n",
    "# Training the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move data to the GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs, _ = resnet18_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Training finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet18_model.state_dict(), 'resnet18_mnist_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model\n",
    "Using the test tensor we initialized above, we can set the model into evaluation mode and then record how accurate it is at making predictions. MNIST in the resnet18 model achieved ~99% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.14%\n"
     ]
    }
   ],
   "source": [
    "# Load the test data\n",
    "mnist_test = pd.read_csv(os.path.join(mnist_directory, \"mnist_test.csv\"), header=None)\n",
    "\n",
    "# Extract labels and pixel values\n",
    "test_labels = mnist_test.iloc[:, 0].values\n",
    "test_images = mnist_test.iloc[:, 1:].values / 255.0  # Normalize pixel values to the range [0, 1]\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "test_images_tensor = torch.tensor(test_images, dtype=torch.float32)\n",
    "test_labels_tensor = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "# Reshape the images to [batch_size, 1, 28, 28]\n",
    "test_images_tensor = test_images_tensor.view(-1, 1, 28, 28)\n",
    "\n",
    "# Move the test data to the GPU\n",
    "test_images_tensor, test_labels_tensor = test_images_tensor.to(device), test_labels_tensor.to(device)\n",
    "\n",
    "# Create TensorDataset and DataLoader for the test data\n",
    "test_dataset = TensorDataset(test_images_tensor, test_labels_tensor)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "resnet18_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs, _ = resnet18_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
