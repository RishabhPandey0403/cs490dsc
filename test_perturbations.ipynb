{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Model Architectures\n",
    "Custom Torch Models need to be instantiated for evaluation. The model_architectures.py file contains the model architectures so we can abstract it and focus only on the evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using device: cuda\n",
      "['BasicBlock', 'DataLoader', 'F', 'Load', 'ResNetCIFAR', 'ResNetMNIST', 'ResnetSVHN', 'TensorDataset', 'Tester', 'Visualizer', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'cifar_directory', 'conv3x3', 'current_directory', 'device', 'mnist_directory', 'nn', 'np', 'os', 'pd', 'pickle', 'plt', 'scipy', 'svhn_directory', 'torch']\n"
     ]
    }
   ],
   "source": [
    "from model_architectures import *\n",
    "import model_architectures\n",
    "from attacks import * \n",
    "# Print available classes to verify our model architectures were imported\n",
    "print(dir(model_architectures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Model Weights\n",
    "Using our model artifacts we load the weights back into the model so we have our pre-trained models to test our perturbations against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_resnet_model = ResNetMNIST(BasicBlock, [2, 2, 2, 2], num_classes=10, grayscale=True).to(device)\n",
    "cifar_resnet_model = ResNetCIFAR(BasicBlock, [2, 2, 2, 2], num_classes=10, grayscale=False).to(device)\n",
    "svhn_resnet_model = ResnetSVHN(BasicBlock, [2, 2, 2, 2], num_classes=10, grayscale=False).to(device)\n",
    "\n",
    "mnist_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_mnist_model.pth\"))\n",
    "cifar_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_cifar_model.pth\"))\n",
    "svhn_resnet_model.load_state_dict(torch.load(\"artifacts/resnet18_svhn_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResnetSVHN(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set models to evaluation mode\n",
    "mnist_resnet_model.eval()\n",
    "cifar_resnet_model.eval()\n",
    "svhn_resnet_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading/Visualizing Data\n",
    "Functionality to load the test dataset and labels as numpy arrays and visualize any given image from the numpy array has been implemented in the model_architectures.py file for easy access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Load()\n",
    "# mnist_test_images, mnist_test_labels = loader.load_mnist_test_images()\n",
    "cifar10_test_images, cifar10_test_labels = loader.load_cifar10_test_images()\n",
    "# svhn_test_images, svhn_test_labels = loader.load_svhn_test_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test visualizer with an image available in test data\n",
    "viz = Visualizer()\n",
    "# # MNIST\n",
    "# i = 1\n",
    "# print(f\"MNIST Shape: {mnist_test_images[i].shape}\")\n",
    "# print(f\"MNIST Label: {mnist_test_labels[i]}\")\n",
    "# viz.show(mnist_test_images[i])\n",
    "\n",
    "# # CIFAR-10\n",
    "# label_mapping = {\n",
    "#     0: 'airplane',\n",
    "#     1: 'automobile',\n",
    "#     2: 'bird',\n",
    "#     3: 'cat',\n",
    "#     4: 'deer',\n",
    "#     5: 'dog',\n",
    "#     6: 'frog',\n",
    "#     7: 'horse',\n",
    "#     8: 'ship',\n",
    "#     9: 'truck'\n",
    "# }\n",
    "# print(f\"\\nCIFAR-10 Shape: {cifar10_test_images[i].shape}\")\n",
    "# print(f\"CIFAR-10 Label: {label_mapping[cifar10_test_labels[i]]}\")\n",
    "# viz.show(cifar10_test_images[i])\n",
    "\n",
    "# # SVHN\n",
    "# print(f\"\\nSVHN Shape: {svhn_test_images[i].shape}\")\n",
    "# print(f\"SVHN Label: {svhn_test_labels[i]}\")\n",
    "# viz.show(svhn_test_images[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Our Models (Unperturbed Data)\n",
    "The data is converted to PyTorch tensors and loaded with a Data Loader for the model to be evaluated. The model can only take in Data Loaders to iterate through the data so after perturbations, we have to load it with the data loader and then evaluate the model. We can verify our models by evaluating the clean test sets and checking the accuracy is equal to our expected accuracies: 99% for MNIST, 76% for CIFAR10, and 93% for SVHN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader_mnist = loader.convert_mnist_numpy_to_tensor(mnist_test_images[:256], mnist_test_labels[:256])\n",
    "test_loader_cifar10 = loader.convert_cifar10_numpy_to_tensor(cifar10_test_images[:256], cifar10_test_labels[:256])\n",
    "# test_loader_svhn = loader.convert_svhn_numpy_to_tensor(svhn_test_images[:256], svhn_test_labels[:256])\n",
    "tester = Tester()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# acc_mnist = tester.test(mnist_resnet_model, test_loader_mnist)\n",
    "# print(f'Test Accuracy MNIST: {acc_mnist * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_cifar10 = tester.test(cifar_resnet_model, test_loader_cifar10)\n",
    "# print(f'Test Accuracy CIFAR10: {acc_cifar10 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_svhn = tester.test(svhn_resnet_model, test_loader_svhn)\n",
    "# print(f'Test Accuracy SVHN: {acc_svhn * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perturbing an Image and Testing Accuracy\n",
    "As a simple test we'll just flip the image so it's reversed. In this process we use perturb to modify the images and then reload it with a Data Loader and test it against our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_flip(images):\n",
    "#     \"\"\"\n",
    "#     Flip images along the specified axis.\n",
    "\n",
    "#     Parameters:\n",
    "#     - images: numpy array with shape (num_images, channels, height, width)\n",
    "#     - axis: Axis along which to flip the images (0 for vertical, 1 for horizontal)\n",
    "\n",
    "#     Returns:\n",
    "#     - Perturbed images\n",
    "#     \"\"\"\n",
    "#     flip_axis = 1\n",
    "\n",
    "#     perturbed_images = np.empty_like(images)\n",
    "#     for i in range(images.shape[0]):\n",
    "#         perturbed_image = np.flip(images[i, 0, :, :], axis=flip_axis)\n",
    "#         perturbed_images[i, 0, :, :] = perturbed_image\n",
    "#     return perturbed_images\n",
    "\n",
    "\n",
    "# flipped_images_array = test_flip(mnist_test_images)\n",
    "# # Show example of the image after being flipped\n",
    "# viz.show(flipped_images_array[1])\n",
    "\n",
    "# flipped_images_tensor = loader.convert_mnist_numpy_to_tensor(flipped_images_array, mnist_test_labels)\n",
    "# acc_mnist_flipped = tester.test(mnist_resnet_model, flipped_images_tensor)\n",
    "# print(f'Test Accuracy MNIST (Flipped): {acc_mnist_flipped * 100:.2f}%')\n",
    "# # Accuracy drops 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast Gradient Sign Method\n",
    "The ``fgsm_attack`` function takes three\n",
    "inputs, *image* is the original clean image ($x$), *epsilon* is\n",
    "the pixel-wise perturbation amount ($\\epsilon$), and *data_grad*\n",
    "is gradient of the loss w.r.t the input image\n",
    "($\\nabla_{x} J(\\mathbf{\\theta}, \\mathbf{x}, y)$). The function\n",
    "then creates perturbed image as\n",
    "\n",
    "\\begin{align}perturbed\\_image = image + epsilon*sign(data\\_grad)\\end{align}\n",
    "\n",
    " \\begin{align}= x + \\epsilon * sign(\\nabla_{x} J(\\mathbf{\\theta}, \\mathbf{x}, y))\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fgsm(model, test_loader, epsilon):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    adv_examples = []\n",
    "    batch = 0\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        batch += 1\n",
    "        print(f\"Batch: {batch}, Epsilon: {epsilon}, Correct: {correct}\")\n",
    "        for image, label in zip(images, labels):\n",
    "            image = image.unsqueeze(0)\n",
    "            label = label.unsqueeze(0)\n",
    "            image.requires_grad = True\n",
    "            output, _ = model(image)\n",
    "\n",
    "            # print(outputs)\n",
    "\n",
    "            _, init_pred = torch.max(output.data, 1)\n",
    "\n",
    "            if not torch.equal(init_pred, label):\n",
    "                continue\n",
    "            \n",
    "            loss = F.nll_loss(output, label)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            data_grad = image.grad.data\n",
    "            perturbed_data = fgsm_attack(image, epsilon, data_grad)\n",
    "\n",
    "            output_final, _ = model(perturbed_data)\n",
    "            _, final_pred = torch.max(output_final.data, 1)\n",
    "            if torch.equal(final_pred, label):\n",
    "                correct += 1\n",
    "                if epsilon == 0 and len(adv_examples) < 5:\n",
    "                    adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                    adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "            else:\n",
    "                # Save some adv examples for visualization later\n",
    "                if len(adv_examples) < 5:\n",
    "                    adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                    adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "            total +=1 \n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Epsilon: {epsilon}\\tTest Accuracy = {correct} / {total} = {accuracy}\")\n",
    "    return accuracy, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0, .05, .1, .15, .2, .25, .5]\n",
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "# # Run test for each epsilon\n",
    "# for eps in epsilons:\n",
    "#     acc, ex = test_fgsm(mnist_resnet_model, test_loader_mnist, eps)\n",
    "#     accuracies.append(acc)\n",
    "#     examples.append(ex)\n",
    "\n",
    "# print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5,5))\n",
    "# plt.plot(epsilons, accuracies, \"*-\")\n",
    "# plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "# plt.xticks(np.arange(0, .55, step=0.05))\n",
    "# plt.title(\"Accuracy vs Epsilon\")\n",
    "# plt.xlabel(\"Epsilon\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# plt.figure(figsize=(8,10))\n",
    "# for i in range(len(epsilons)):\n",
    "#     for j in range(len(examples[i])):\n",
    "#         cnt += 1\n",
    "#         plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
    "#         plt.xticks([], [])\n",
    "#         plt.yticks([], [])\n",
    "#         if j == 0:\n",
    "#             plt.ylabel(f\"Eps: {epsilons[i]}\", fontsize=14)\n",
    "#         orig,adv,ex = examples[i][j]\n",
    "#         plt.title(f\"{orig} -> {adv}\")\n",
    "#         plt.imshow(ex, cmap=\"gray\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_deepfool(model, test_loader, overshoot=0.02):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    adv_examples = []\n",
    "    batch = 0\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        batch += 1\n",
    "        print(f\"Batch: {batch}, Correct: {correct}\")\n",
    "        for image, label in zip(images, labels):\n",
    "            image = image.unsqueeze(0)\n",
    "            label = label.unsqueeze(0)\n",
    "            image.requires_grad = True\n",
    "            output, _ = model(image)\n",
    "\n",
    "            # print(outputs)\n",
    "\n",
    "            _, init_pred = torch.max(output.data, 1)\n",
    "\n",
    "            if not torch.equal(init_pred, label):\n",
    "                continue\n",
    "            \n",
    "            perturbed_image, final_pred, r_total, iter = deepfool_attack(image, model, overshoot=0.02, max_iterations=100)\n",
    "            print(f\"Perturbed Iteration: {iter}\")\n",
    "            if torch.equal(final_pred, label):\n",
    "                correct += 1\n",
    "            total +=1 \n",
    "            # TODO: Remove\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy = {correct} / {total} = {accuracy}\")\n",
    "    return accuracy, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1, Correct: 0\n",
      "Perturbed Iteration: 22\n",
      "Perturbed Iteration: 15\n",
      "Perturbed Iteration: 77\n",
      "Perturbed Iteration: 14\n",
      "Perturbed Iteration: 66\n",
      "Perturbed Iteration: 28\n",
      "Perturbed Iteration: 70\n",
      "Perturbed Iteration: 57\n",
      "Perturbed Iteration: 18\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 93\n",
      "Perturbed Iteration: 32\n",
      "Perturbed Iteration: 43\n",
      "Perturbed Iteration: 56\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 48\n",
      "Perturbed Iteration: 45\n",
      "Perturbed Iteration: 15\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 41\n",
      "Perturbed Iteration: 53\n",
      "Perturbed Iteration: 93\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 25\n",
      "Perturbed Iteration: 38\n",
      "Perturbed Iteration: 8\n",
      "Perturbed Iteration: 56\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 61\n",
      "Perturbed Iteration: 79\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 2\n",
      "Perturbed Iteration: 72\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 22\n",
      "Perturbed Iteration: 58\n",
      "Perturbed Iteration: 39\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 30\n",
      "Perturbed Iteration: 19\n",
      "Perturbed Iteration: 69\n",
      "Perturbed Iteration: 96\n",
      "Perturbed Iteration: 33\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 58\n",
      "Perturbed Iteration: 92\n",
      "Perturbed Iteration: 23\n",
      "Perturbed Iteration: 82\n",
      "Perturbed Iteration: 67\n",
      "Perturbed Iteration: 12\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 89\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 45\n",
      "Perturbed Iteration: 61\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 79\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 68\n",
      "Perturbed Iteration: 72\n",
      "Perturbed Iteration: 75\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 90\n",
      "Perturbed Iteration: 85\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 97\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 59\n",
      "Perturbed Iteration: 82\n",
      "Perturbed Iteration: 30\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 84\n",
      "Perturbed Iteration: 39\n",
      "Perturbed Iteration: 15\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 89\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 68\n",
      "Perturbed Iteration: 56\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 96\n",
      "Perturbed Iteration: 75\n",
      "Perturbed Iteration: 18\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 63\n",
      "Perturbed Iteration: 5\n",
      "Perturbed Iteration: 90\n",
      "Perturbed Iteration: 53\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 84\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 88\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 36\n",
      "Perturbed Iteration: 66\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 44\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 41\n",
      "Perturbed Iteration: 65\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 79\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 24\n",
      "Perturbed Iteration: 83\n",
      "Perturbed Iteration: 63\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 97\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 47\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 2\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 81\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 37\n",
      "Perturbed Iteration: 28\n",
      "Perturbed Iteration: 78\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 23\n",
      "Perturbed Iteration: 44\n",
      "Perturbed Iteration: 16\n",
      "Perturbed Iteration: 68\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 57\n",
      "Perturbed Iteration: 9\n",
      "Perturbed Iteration: 89\n",
      "Perturbed Iteration: 39\n",
      "Perturbed Iteration: 58\n",
      "Perturbed Iteration: 28\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 46\n",
      "Perturbed Iteration: 32\n",
      "Perturbed Iteration: 17\n",
      "Perturbed Iteration: 12\n",
      "Perturbed Iteration: 66\n",
      "Perturbed Iteration: 66\n",
      "Perturbed Iteration: 91\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 65\n",
      "Perturbed Iteration: 92\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 43\n",
      "Perturbed Iteration: 8\n",
      "Perturbed Iteration: 86\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 4\n",
      "Perturbed Iteration: 43\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 27\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 13\n",
      "Perturbed Iteration: 56\n",
      "Perturbed Iteration: 11\n",
      "Perturbed Iteration: 11\n",
      "Perturbed Iteration: 63\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 3\n",
      "Perturbed Iteration: 47\n",
      "Perturbed Iteration: 72\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 72\n",
      "Perturbed Iteration: 5\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 69\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 32\n",
      "Perturbed Iteration: 17\n",
      "Perturbed Iteration: 42\n",
      "Perturbed Iteration: 100\n",
      "Perturbed Iteration: 66\n",
      "Perturbed Iteration: 66\n",
      "Test Accuracy = 70 / 197 = 0.3553299492385787\n"
     ]
    }
   ],
   "source": [
    "accuracy = test_deepfool(cifar_resnet_model, test_loader_cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
